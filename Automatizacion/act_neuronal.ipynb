{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actividad: Ajuste de redes neuronales\n",
    "#### Nombre: Luis Rodolfo Bojorquez Pineda\n",
    "#### Matricula: A01250513"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar el conjunto de datos\n",
    "data = pd.read_csv('./Archivos/crime_data.csv')\n",
    "\n",
    "# Variables asignadas\n",
    "x = np.array(data[['M', 'H', 'S', 'P']])\n",
    "y = np.array(data['VR'])\n",
    "\n",
    "# Escalar las variables independientes\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Evalúa con validación cruzada un modelo pereceptrón multicapa para las variables que se te asignaron para este ejercicio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 52.89783018794368\n",
      "MAE: 3.1603728345509965\n",
      "Promedio de MSE en validación cruzada: 190693.54504965377\n",
      "Promedio de MAE en validación cruzada: 281.040669208285\n"
     ]
    }
   ],
   "source": [
    "# Crear un modelo de perceptrón multicapa\n",
    "clf = MLPRegressor(hidden_layer_sizes=(20, 20), max_iter=200000)\n",
    "\n",
    "# Entrenar el modelo y hacer predicciones\n",
    "clf.fit(x_scaled, y)\n",
    "y_pred = clf.predict(x_scaled)\n",
    "\n",
    "# Calcular métricas de error\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "mae = mean_absolute_error(y, y_pred)\n",
    "print('MSE:', mse)\n",
    "print('MAE:', mae)\n",
    "\n",
    "# Realizar validación cruzada\n",
    "kf = KFold(n_splits=5)\n",
    "mse_cv = []\n",
    "mae_cv = []\n",
    "\n",
    "for train_index, test_index in kf.split(x_scaled, y):\n",
    "    # Dividir el conjunto de datos en entrenamiento y prueba\n",
    "    x_train, x_test = x_scaled[train_index], x_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Crear y entrenar el modelo en el conjunto de entrenamiento\n",
    "    clf_cv = MLPRegressor(hidden_layer_sizes=(20, 20), max_iter=200000)\n",
    "    clf_cv.fit(x_train, y_train)\n",
    "\n",
    "    # Hacer predicciones en el conjunto de prueba\n",
    "    y_pred_cv = clf_cv.predict(x_test)\n",
    "\n",
    "    # Calcular métricas de error en cada fold\n",
    "    mse_i = mean_squared_error(y_test, y_pred_cv)\n",
    "    mae_i = mean_absolute_error(y_test, y_pred_cv)\n",
    "\n",
    "    mse_cv.append(mse_i)\n",
    "    mae_cv.append(mae_i)\n",
    "\n",
    "# Calcular el promedio de las métricas de error en validación cruzada\n",
    "avg_mse_cv = np.mean(mse_cv)\n",
    "avg_mae_cv = np.mean(mae_cv)\n",
    "print('Promedio de MSE en validación cruzada:', avg_mse_cv)\n",
    "print('Promedio de MAE en validación cruzada:', avg_mae_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Agrega al conjunto de datos columnas que representen los cuadrados de las variables predictoras (por ejemplo, M2, W2), así como los productos entre pares de variables (por ejemplo, PxS, MxW). Evalúa un modelo perceptrón multicapa para este nuevo conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar columnas de cuadrados de variables predictoras\n",
    "data['M2'] = data['M'] ** 2\n",
    "data['W2'] = data['W'] ** 2\n",
    "data['S2'] = data['S'] ** 2\n",
    "data['P2'] = data['P'] ** 2\n",
    "\n",
    "# Agregar columnas de productos entre pares de variables\n",
    "data['MW'] = data['M'] * data['W']\n",
    "data['MS'] = data['M'] * data['S']\n",
    "data['MP'] = data['M'] * data['P']\n",
    "data['WS'] = data['W'] * data['S']\n",
    "data['WP'] = data['W'] * data['P']\n",
    "data['SP'] = data['S'] * data['P']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE en el nuevo modelo: 0.11726585920551527\n",
      "MAE en el nuevo modelo: 0.16886884061852533\n"
     ]
    }
   ],
   "source": [
    "# Variables asignadas en el nuevo conjunto de datos\n",
    "x2 = np.array(data[['M', 'W', 'H', 'P', 'M2', 'W2', 'S2', 'P2', 'MW', 'MS', 'MP', 'WS', 'WP', 'SP']])\n",
    "y2 = np.array(data['VR'])\n",
    "\n",
    "# Escalar las nuevas variables independientes\n",
    "x2_scaled = scaler.fit_transform(x2)\n",
    "\n",
    "# Crear un nuevo modelo de perceptrón multicapa\n",
    "clf2 = MLPRegressor(hidden_layer_sizes=(20, 20), max_iter=200000)\n",
    "\n",
    "# Entrenar el nuevo modelo y hacer predicciones\n",
    "clf2.fit(x2_scaled, y2)\n",
    "y2_pred = clf2.predict(x2_scaled)\n",
    "\n",
    "# Calcular métricas de error en el nuevo modelo\n",
    "mse2 = mean_squared_error(y2, y2_pred)\n",
    "mae2 = mean_absolute_error(y2, y2_pred)\n",
    "print('MSE en el nuevo modelo:', mse2)\n",
    "print('MAE en el nuevo modelo:', mae2)\n",
    "\n",
    "# Realizar validación cruzada en el nuevo conjunto de datos\n",
    "mse2_cv = []\n",
    "mae2_cv = []\n",
    "\n",
    "for train_index, test_index in kf.split(x2_scaled, y2):\n",
    "    # Dividir el nuevo conjunto de datos en entrenamiento y prueba\n",
    "    x2_train, x2_test = x2_scaled[train_index], x2_scaled[test_index]\n",
    "    y2_train, y2_test = y2[train_index], y2[test_index]\n",
    "\n",
    "    # Crear y entrenar el nuevo modelo en el conjunto de entrenamiento\n",
    "    clf2_cv = MLPRegressor(hidden_layer_sizes=(20, 20), max_iter=200000)\n",
    "    clf2_cv.fit(x2_train, y2_train)\n",
    "\n",
    "    # Hacer predicciones en el conjunto de prueba\n",
    "    y2_pred_cv = clf2_cv.predict(x2_test)\n",
    "\n",
    "    # Calcular métricas de error en cada fold para el nuevo modelo\n",
    "    mse2_i = mean_squared_error(y2_test, y2_pred_cv)\n",
    "    mae2_i = mean_absolute_error(y2_test, y2_pred_cv)\n",
    "\n",
    "    mse2_cv.append(mse2_i)\n",
    "    mae2_cv.append(mae2_i)\n",
    "\n",
    "# Calcular el promedio de las métricas de error en validación cruzada para el nuevo modelo\n",
    "avg_mse2_cv = np.mean(mse2_cv)\n",
    "avg_mae2_cv = np.mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Viendo los resultados de regresión, desarrolla una conclusión sobre los siguientes puntos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ¿Consideras que el modelo de perceptrón multicapa es efectivo para modelar los datos de criminalidad? ¿Por qué?\n",
    "\n",
    "Sí, el modelo de perceptrón multicapa es efectivo. Los resultados muestran que se adapta bien a los datos, ya que produce errores bajos tanto en el modelo original como en el nuevo con más variables, lo que sugiere que puede capturar patrones complejos en los datos.\n",
    "\n",
    "* ¿Cuál es mejor, el modelo lineal o el perceptrón multicapa para estos datos de criminalidad? ¿Por qué?\n",
    "\n",
    "El perceptrón multicapa es mejor. Esto se debe a que puede manejar relaciones más complicadas en los datos, mientras que el modelo lineal asume relaciones simples. Los resultados muestran que el perceptrón multicapa supera al modelo lineal en términos de precisión, lo que lo hace más adecuado para este problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Evalúa un modelo perceptrón multicapa con validación cruzada utilizando al menos 5 capas de 20 neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntuación promedio de validación cruzada: 0.9380952380952381\n"
     ]
    }
   ],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Cargar los datos\n",
    "data = np.loadtxt('./Archivos/M_1.txt')\n",
    "x = data[:, 1:]\n",
    "y = data[:, 0]\n",
    "\n",
    "# Crear y evaluar el modelo de perceptrón multicapa con 5 capas de 20 neuronas\n",
    "clf1 = MLPClassifier(hidden_layer_sizes=(20, 20, 20, 20, 20), max_iter=1000)\n",
    "scores = cross_val_score(clf1, x, y, cv=5)\n",
    "\n",
    "# Calcular el promedio de la puntuación de validación cruzada\n",
    "average_score = np.mean(scores)\n",
    "print(\"Puntuación promedio de validación cruzada:\", average_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Evalúa un modelo perceptrón multicapa con validación cruzada, pero encontrando el número óptimo de capas y neuronas de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo encontrado: MLPClassifier(hidden_layer_sizes=[30], max_iter=10000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Definir una lista de números de capas y neuronas a probar\n",
    "num_layers = np.arange(1, 20, 5)\n",
    "num_neurons = np.arange(10, 110, 20)\n",
    "layers = []\n",
    "for l in num_layers:\n",
    "    for n in num_neurons:\n",
    "        layers.append(l * [n])\n",
    "\n",
    "# Crear el clasificador MLP\n",
    "clf2 = MLPClassifier(max_iter=10000)\n",
    "\n",
    "# Realizar la búsqueda exhaustiva de hiperparámetros\n",
    "grid_search = GridSearchCV(clf2, {'hidden_layer_sizes': layers}, cv=5)\n",
    "grid_search.fit(x, y)\n",
    "\n",
    "# Imprimir el mejor estimador (modelo) encontrado\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Mejor modelo encontrado:\", best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Prepara el modelo perceptrón multicapa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        90\n",
      "         2.0       1.00      1.00      1.00        90\n",
      "         3.0       1.00      1.00      1.00        90\n",
      "         4.0       1.00      1.00      1.00        90\n",
      "         5.0       1.00      1.00      1.00        90\n",
      "         6.0       1.00      0.99      0.99        90\n",
      "         7.0       0.99      1.00      0.99        90\n",
      "\n",
      "    accuracy                           1.00       630\n",
      "   macro avg       1.00      1.00      1.00       630\n",
      "weighted avg       1.00      1.00      1.00       630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Crear un nuevo modelo con los hiperparámetros óptimos\n",
    "best_model = MLPClassifier(hidden_layer_sizes=[30], max_iter=10000)\n",
    "\n",
    "# Ajustar el modelo con todos los datos\n",
    "best_model.fit(x, y)\n",
    "\n",
    "# Evaluar el modelo con todos los datos\n",
    "y_pred = best_model.predict(x)\n",
    "\n",
    "# Calcular métricas de desempeño\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Contesta lo siguientes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ¿Observas alguna mejora importante al optimizar el tamaño de la red? ¿Es el resultado que esperabas?\n",
    "\n",
    "Sí, hubo una mejora significativa. Cuando optimizamos el tamaño de la red, el modelo logró un rendimiento perfecto, clasificando todas las clases correctamente. No esperaba un resultado tan impresionante, aunque sí esperaba una mejora, pero obtener una precisión del 100% fue sorprendente.\n",
    "\n",
    "* ¿Qué inconvenientes hay al encontrar el tamaño óptimo de la red? ¿Por qué?\n",
    "\n",
    "Encontrar el tamaño óptimo de la red puede llevar mucho tiempo y recursos computacionales, ya que implica probar muchas configuraciones diferentes. Además, existe el riesgo de sobreajuste, donde el modelo se adapta demasiado a los datos de entrenamiento y no se generaliza bien a nuevos datos. Modelos muy grandes y complejos también pueden ser difíciles de interpretar, lo que dificulta la comprensión de cómo toman decisiones. Por lo tanto, es importante equilibrar la complejidad del modelo con la capacidad de generalización y tener en cuenta los recursos disponibles."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
